{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"Preprocess_Analog_Training_Data_3.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"QiaUmmfUeBZb","colab_type":"text"},"source":["# Preprocess Analog Data Inputs\n","\n","The Required format for the model is a grayscaled 224x224 image. This notebook converts all the files in a folder into this format"]},{"cell_type":"markdown","metadata":{"id":"Wp_QNwJhqHoI","colab_type":"text"},"source":["### Set Up connection with Google Drive"]},{"cell_type":"code","metadata":{"id":"2wz6rS_LqS88","colab_type":"code","outputId":"056241b0-c5ce-4874-8c7d-cd78e5e1011e","executionInfo":{"status":"ok","timestamp":1569319354451,"user_tz":-120,"elapsed":47709,"user":{"displayName":"Akshay SUNDAR","photoUrl":"","userId":"03064570403919925052"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2Log61bqE7T","colab_type":"text"},"source":["### Import Dependencies\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"OC26D1xoqE8F","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","from random import shuffle\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","import tensorflow as tf\n","import cv2\n","import shutil"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q9A-TWP3qE8f","colab_type":"text"},"source":["### Create Function that Resizes Image to 224x224"]},{"cell_type":"code","metadata":{"id":"SJA2kfn0qE87","colab_type":"code","colab":{}},"source":["def image_resizer(input_file,c1,c2):\n","    \"\"\"\n","    Inputs - \n","    input_file - Image file to be processed\n","    c1 - Width of image shape\n","    c2 - Height dimension of image shape\n","    \n","    Process - \n","    In case of digits where the image is very low width, a buffer is added on the left and right of the image\n","    \n","    This is done by repeating the leftmost column n times and the rightmost column m times so that the output dimension is 224 on width\n","    \n","    This is followed by a simple resize to make the height 224\n","    \n","    The padding on the left and right is done since in most cases of the digit '1', a simple resize would distort the image\n","    \n","    Output -\n","    Processed Image in the right dimensions\n","    \n","    \"\"\"\n","    adj = input_file\n","\n","    if adj.shape[1]<c1:\n","        addit_r  = int(np.floor((c1-adj.shape[1])/2))\n","        rightadd = np.repeat(adj[:,-1],addit_r).reshape(len(adj[:,-1]),addit_r)\n","        addit_l  = int(np.ceil((c1-adj.shape[1])/2))\n","        leftadd  = np.repeat(adj[:,0],addit_l).reshape(len(adj[:,0]),addit_l)\n","        \n","        adj = np.concatenate((leftadd,adj,rightadd),axis=1)\n","\n","    \n"," \n","    adj = cv2.resize(adj,(c1,c2),interpolation=cv2.INTER_AREA)\n","  \n","    return adj"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCkkCm2QqE84","colab_type":"text"},"source":["### Processing the Analog Data"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"xT3JuEpSqE9E","colab_type":"code","colab":{}},"source":["# Setting Input Locations for training and validation data\n","\n","analog_dir_tr = \"/content/drive/My Drive/Team Bergere/Optimizer/Data/optimizer/HQ_analog/Split/Train/\"\n","analog_dir_ts = \"/content/drive/My Drive/Team Bergere/Optimizer/Data/optimizer/HQ_analog/Split/Test/\"\n","\n","# Setting Output Locations for training and validation data\n","analog_dir_trou = \"/content/drive/My Drive/Team Bergere/Optimizer/Data/optimizer/HQ_analog/Split/Train_proc/\"\n","analog_dir_tsou = \"/content/drive/My Drive/Team Bergere/Optimizer/Data/optimizer/HQ_analog/Split/Test_proc/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"bs63E5GPqE8i","colab_type":"code","colab":{}},"source":["# Setting Parameters\n","\n","\n","# Distionary with class names from 0 to 10\n","classrange = dict()\n","\n","for i in range(11):\n","    classrange[i] = str(i)+'/'\n","\n","# Required target size of 224x224    \n","target_size = (224, 224)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7AQMO9mr5d-","colab_type":"text"},"source":["### Define function that Reads, Processes and Writes Images from a given Directory to an output directory"]},{"cell_type":"code","metadata":{"id":"IzeXYxFHrscl","colab_type":"code","colab":{}},"source":["\n","def proc_image(loc,outp):\n","\n","  \"\"\"\n","  Inputs - \n","  loc  - Input file location\n","  outp - Output File location\n","\n","  Process - \n","  The file is loaded using the OpenCV package and greyscaled\n","  \n","  Then it is resized using the previously defined function\n","  \n","  It is then written into the output directory\n","\n","  Output -\n","  No output\n","\n","  \"\"\"\n","  \n","  counter = 0\n","  for file in os.listdir(loc):\n","    if \"png\" in file or 'jpg' in file and 'augmented' not in file and counter<1000:\n","      img_tc1 = cv2.imread(loc+file)\n","      img_tc1 = cv2.cvtColor(img_tc1, cv2.COLOR_BGR2GRAY)\n","      temp = image_resizer(img_tc1,target_size[0],target_size[1])\n","      cv2.imwrite(outp+file,temp)\n","      counter = counter+1\n","  return 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KJoBNr8sfej","colab_type":"text"},"source":["### Loop through the class-wise directories and process images"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"elhAJEH1qE9a","colab_type":"code","outputId":"86d8ed5b-2cbb-4571-ac6a-b2e3e4564bff","executionInfo":{"status":"ok","timestamp":1569319855928,"user_tz":-120,"elapsed":232941,"user":{"displayName":"Akshay SUNDAR","photoUrl":"","userId":"03064570403919925052"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Load Analog files\n","\n","for i in range(0,11):\n","    proc_image(analog_dir_tr+classrange[i],analog_dir_trou+classrange[i])\n","    print(str(i)+' 1')\n","    "],"execution_count":10,"outputs":[{"output_type":"stream","text":["0 1\n","1 1\n","2 1\n","3 1\n","4 1\n","5 1\n","6 1\n","7 1\n","8 1\n","9 1\n","10 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vazb1HsAspJq","colab_type":"text"},"source":["### Result - The set of images from the input locations are processed and written to the output location."]},{"cell_type":"code","metadata":{"id":"B9HfPAz1s60r","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}